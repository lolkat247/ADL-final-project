# Voice Conversion with Autoencoder + HiFi-GAN

This project aims to perform voice conversion using a content encoder + speaker embedding architecture and HiFi-GAN for waveform synthesis. The goal is to take the **content of one speaker's voice** and **convert it into the sound of another speaker**.

## Overview

The system consists of three main components:

1. **Autoencoder (AE)**  
   - Encoder: Extracts content representation from Mel-spectrograms  
   - Decoder: Reconstructs Mel-spectrograms using content + target speaker embedding

2. **Speaker Embeddings**  
   - We use ECAPA-TDNN from SpeechBrain to extract speaker embeddings from a short reference clip of the target voice.
   - This allows the model to generate Mel-spectrograms that match the voice characteristics of any speaker given just a few seconds of their speech.
   - See `common/speaker_embed.py` for the implementation.

3. **HiFi-GAN Vocoder**  
   - Converts Mel-spectrograms back into high-quality audio

## Project Structure
```
voice-conversion/
â”œâ”€â”€ common/                # Shared utilities
â”‚   â”œâ”€â”€ audio_utils.py     # Load/save audio
â”‚   â”œâ”€â”€ mel_spectrogram.py # Feature extraction
â”‚   â”œâ”€â”€ speaker_embed.py   # Speaker embedding module
â”‚   â””â”€â”€ model.py           # AE model architecture
â”‚
â”œâ”€â”€ inference/             # Inference and real-time conversion
â”‚   â”œâ”€â”€ inference_pipeline.py
â”‚   â”œâ”€â”€ vocoder.py
â”‚   â”œâ”€â”€ convert.py
â”‚   â””â”€â”€ realtime.py
â”‚
â”œâ”€â”€ training/                # Model training
â”‚   â””â”€â”€ training_loop.ipynb
â”‚
â””â”€â”€ README.md
```
## Quickstart

### Clone Repo & Install Dependencies

```bash
git clone https://github.com/yourusername/voice-conversion.git
cd voice-conversion
pip install -r requirements.txt
```
### Train the Autoencoder

Open and run the training notebook: `training/training_loop.ipynb`

### Convert Audio
```bash
python inference/convert.py \
  --input audio.wav \
  --output converted.wav \
  --ae_ckpt checkpoints/autoencoder.pth \
  --vocoder_ckpt checkpoints/hifigan.pt \
  --speaker_id 0
```

### Real-Time Conversion

Weâ€™ll use sounddevice or pyaudio to stream mic â†’ model â†’ speaker.

## ğŸ§ª Architecture Summary
```
             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 Audio Input â”‚              â”‚
 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚MelSpectrogramâ”‚
             â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â–¼
             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
             â”‚   Encoder    â”‚â”€â”€â”€â”€â”€â”€â”€â”
             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
                                    â–¼
                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 Speaker ID â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚ Speaker Embedder â”‚
                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                         â”‚     Decoder      â”‚
                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â–¼
                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                         â”‚     HiFi-GAN     â”‚
                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â–¼
                         Synthesized Output
```

## ğŸ™ Credits
* HiFi-GAN
* LibriTTS Dataset
* VCTK Corpus